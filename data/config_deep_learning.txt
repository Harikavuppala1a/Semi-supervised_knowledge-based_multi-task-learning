model_types = ["hier_fuse"];
word_feats_l = [[{'emb': 'elmo', 's_enc': 'rnn', 'm_id': '11'}, {'emb': 'glove', 's_enc': 'rnn', 'm_id': '21'}]];
sent_enc_feats_l = [[{'emb': 'bert_pre', 'm_id': '1'}]];
num_cnn_filters = [100]; rnn_dims = [300]; att_dims = [600];
rnn_types = ['lstm']; stack_rnn_flags = [False]; threshes = [0]; cnn_kernel_sets = [[2,3,4]];max_pool_k_vals = [1];
prob_trans_types = ["di"]; class_imb_flags = [True];
**********
test_mode = True
gen_att = False
gen_inst_res = 	True
insights_iteration = False
augment_data = False
merge = False
cascade = True
slightcascade = False
use_knowledge = True
use_wordlevel_knowledge = False
transfer_learning = True
meaning_pickle_filename = "wordmeanings.pickle"

use_conf_scores = False
gen_conf_scores = False
scale_value =0.0
scaling_confscores = "None"
conf_score_filename_list = []

single_inp_tasks_list = [("topic",{"filename":"topic_vecs.pickle","loss_func":"mean_squared_error","loss_weight":0.1}),("kmeans",{"filename":"kmeans~5.pickle","n_clusters":5,"loss_weight":0.1})]
sep_inp_tasks_list = [("sd",{"filename":"sexismDet.txt","loss_weight":0.1}),("sarcasm",{"filename":"sarcasm.txt","loss_weight":0.1}),("emotion",{"filename":"emotion.txt","loss_weight":0.1,"n_labels":11})]
classi_loss_weight = 1.0
multi_task_tl = "multi_task"
share_weights_sep_mt = True

train_ratio = 1
uncorr_c_pairs_filename = "corr_fuzzy_0.05.pickle"
beta = 0.05
label_corr_setting = "l1_fuzzy_0.05"

confidence_thr = 0.0
st_variant = "None"
retaining_ratio = 0.0

GPU_ID = '4'

use_saved_model = True 
save_model = True

use_saved_sent_enc_feats = True
save_sent_enc_feats = True

use_saved_word_feats = True
save_word_feats = True

poss_sent_enc_feats_emb_dict = {'use': 512, 'infersent': 4096, 'bert': 1024, 'bert_pre': 768,'trainable_bert' : 768, 'perspective':10, 'hurtlex':20}
poss_word_feats_emb_dict = {'glove': 300, 'ling': 33, 'elmo': 3072, 'fasttext': 300, 'hurtlex':20}

dropO1 = 0.25
dropO2 = 0.25
LEARN_RATE = 0.001

BATCH_SIZE = 64
EPOCHS = 10
num_runs_list = [3]
MAX_WORDS_SENT = 35
MAX_SENT = 16
MAX_WORDS_POST = 198
RANDOM_STATE = 22
TEST_RATIO = 0.15
VALID_RATIO = 0.15

bert_max_seq_len= 100
max_num_pred_labs = 7
min_num_pred_labs = 4
max_weak_lab_support = 1300

bert_max_seq_len = 64
bert_path = "saved/tbert-hubmodule"
tbert_paths = {"config_path" : "../bert/tmp/bert_model/bert_config.json", "vocab_path" : "../bert/tmp/bert_model/vocab.txt", "ckpt_path" : "../bert/tmp/bert_model/model.ckpt-100000"}
n_fine_tune_layers = 3 
output_representation = "sequence_output"
bert_trainable = True

weaklabel_filename = 'Unlabeled_data_weaklabels.txt'
sd_filename = "sexismDet.txt"
filename = 'sexismClassi.csv'
res_filename = "results1.txt"
filename_map_list = ['23_class_maps.txt']
res_tsv_filename = "delete_tsv1.txt"
output_folder_name = "results/"
data_folder_name = "data/"
save_folder_name = "saved/"
